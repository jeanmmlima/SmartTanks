{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMART TANKS\n",
    "### Coupled tanks simulator based on machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n",
    "\n",
    "#function to scale the dataset\n",
    "def scaleData(data):\n",
    "    s_data = data.copy()\n",
    "    l = len(s_data.T)\n",
    "    for i in range(l):\n",
    "        s_data.iloc[:,i] = ((data.iloc[:,i] - data.iloc[:,i].min())\n",
    "                          / (data.iloc[:,i].max() - data.iloc[:,i].min()))\n",
    "    return s_data\n",
    "\n",
    "#function to standardize the dataset\n",
    "def standardizeData(data):\n",
    "    s_data = data.copy()\n",
    "    l = len(s_data.T)\n",
    "    for i in range(l):\n",
    "        s_data.iloc[:,i] = ((data.iloc[:,i] - data.iloc[:,i].mean())\n",
    "                          / data.iloc[:,i].std())\n",
    "    \n",
    "    return s_data\n",
    "\n",
    "#function to reStand data\n",
    "def reStandData(data,y,n_inputs,n_outputs):\n",
    "    s_y = y.copy()\n",
    "    outs = data.iloc[:,n_inputs:n_inputs+n_outputs]\n",
    "    y_m = np.matrix(y)\n",
    "    l = len(outs.T)\n",
    "    for i in range(l):\n",
    "        s_y = y_m[i,:] * outs.iloc[:,i].std() + outs.iloc[:,i].mean()\n",
    "        \n",
    "    \n",
    "    return np.array(s_y)\n",
    "\n",
    "#function to add previous values as features\n",
    "def addFeatures(data, n, names):\n",
    "    l = len(data.T)\n",
    "    for i in range(l):\n",
    "        for j in range(n):\n",
    "            #names for delayed inputs\n",
    "            #Ex: Input Gas Rate (-1)...\n",
    "            txt = names[i]+' (-'+str(j+1)+')'\n",
    "            if j == 0:\n",
    "                data[txt] = data[names[i]].shift(periods=1)\n",
    "            else:\n",
    "                txt2 = names[i]+' (-'+str(j)+')'\n",
    "                data[txt] = data[txt2].shift(periods=1)\n",
    "            \n",
    "            data.loc[0,txt] = data.loc[1,txt]\n",
    "            \n",
    "        \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "#split data into X and y\n",
    "def getPairs(fData, n_inputs, n_outputs):\n",
    "    x = fData.iloc[:,0:n_inputs]\n",
    "    delayed_x = fData.iloc[:,n_inputs+n_outputs:]\n",
    "    X = pd.concat([x,delayed_x], axis=1)\n",
    "    y = fData.iloc[:,n_inputs:n_inputs+n_outputs]\n",
    "    return X,y\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#getting (shuffled) train and test sets \n",
    "def getTrainTest(X,Y,samples_train=0.85, shuffle=0):\n",
    "    if(shuffle):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=1-samples_train,random_state=1)\n",
    "        return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "    else:\n",
    "        train_size = int(len(X) * samples_train)\n",
    "        test_size = len(X) - train_size\n",
    "        X_train, X_test = X.iloc[0:train_size],X.iloc[train_size:train_size+test_size]\n",
    "        y_train, y_test = Y.iloc[0:train_size],Y.iloc[train_size:train_size+test_size]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def getTrainTestNoDF(X,Y,samples_train=0.85):\n",
    "    train_size = int(len(X) * samples_train)\n",
    "    test_size = len(X) - train_size\n",
    "    X_train, X_test = X[0:train_size],X[train_size:train_size+test_size]\n",
    "    y_train, y_test = Y[0:train_size],Y[train_size:train_size+test_size]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "        \n",
    "def plotOuts(y_pred, y_test, title):\n",
    "    l = len(y_pred.T)\n",
    "    for i in range(l):\n",
    "        plt.figure(i)\n",
    "        plt.plot(y_pred[:,i])\n",
    "        plt.plot(y_test[:,i])\n",
    "        plt.xlabel('Sample');\n",
    "\n",
    "\n",
    "def getLearningCurve(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'], label='train')\n",
    "    plt.plot(history['val_loss'], label='test')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "import pickle\n",
    "\n",
    "def saveHistoryTrain(folder,name,emq,history,verbose=0):\n",
    "    with open('models/'+str(folder)+'/histories/'+str(name)+'_'+str(emq), 'wb') as file_pi:\n",
    "        pickle.dump(history, file_pi)\n",
    "    if(verbose):    \n",
    "        print(\"Hist√≥rico de trainamento salvo\")\n",
    "        \n",
    "        \n",
    "def loadHistoryTrain():\n",
    "    history = pickle.load(open('models/histories/ST_'+str(best_ss['emq']), \"rb\"))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93322, 2)\n",
      "Data shape:  (93322, 12) (93322,)\n",
      "Supervised phase traning and test: (X) (46661, 12) (46661, 12)\n",
      "Traning and Test: (y) (46661,) (46661,)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "import time\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 16,10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "############\n",
    "\n",
    "#path to access the dataset .txt or .csv\n",
    "path = 'tankdata.csv'\n",
    "\n",
    "#data from pandas\n",
    "tankdata = pd.read_csv(path)\n",
    "print(tankdata.shape)\n",
    "\n",
    "\n",
    "#order of features\n",
    "n_features = 6\n",
    "n_inputs = 1\n",
    "n_outputs = 1\n",
    "\n",
    "#Adicionando features aos dados\n",
    "fTD = addFeatures(tankdata, n_features, tankdata.columns)\n",
    "X = fTD.iloc[:,2:]\n",
    "y = tankdata.L2\n",
    "print(\"Data shape: \",X.shape, y.shape)\n",
    "\n",
    "#Segment the data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "#Standardize the data set.\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"Supervised phase traning and test: (X)\", X_train.shape, X_test.shape)\n",
    "print(\"Traning and Test: (y)\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sklearn Models for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinerRegression: 0.022162, 0.0000\n",
      "Ridge: 0.022160, 0.0000\n",
      "Lasso: 0.024966, 0.0000\n",
      "Random Forrest: 0.022864, 0.0000\n",
      "GBDT: 0.407087, 0.0000\n",
      "Support Vector Regression: 0.070759, 0.0000\n",
      "ElasticNet: 0.054883, 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Introduce algorithms.\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LinearRegression, ElasticNet\n",
    "#Compared with SVC, it is the regression form of SVM.\n",
    "from sklearn.svm import SVR\n",
    "#Integrate algorithms.\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "#Set the model name.\n",
    "names = ['LinerRegression',\n",
    "       'Ridge',\n",
    "       'Lasso',\n",
    "       'Random Forrest',\n",
    "       'GBDT',\n",
    "       'Support Vector Regression',\n",
    "       'ElasticNet']\n",
    "\n",
    "#Define the model.\n",
    "# cv is the cross-validation idea here.\n",
    "models = [LinearRegression(),\n",
    "         RidgeCV(alphas=(0.001,0.1,1),cv=3),\n",
    "         LassoCV(alphas=(0.001,0.1,1),cv=5),\n",
    "         RandomForestRegressor(n_estimators=10),\n",
    "         GradientBoostingRegressor(n_estimators=30),\n",
    "         SVR(),\n",
    "         ElasticNet(alpha=0.001,max_iter=10000)]\n",
    "# Output the R2 scores of all regression models.\n",
    "\n",
    "#Define the R2 scoring function.\n",
    "def RMSE(model,x_train, x_test, y_train, y_test):\n",
    "\n",
    "        model_fitted = model.fit(x_train,y_train)\n",
    "        y_pred = model_fitted.predict(x_test)\n",
    "        score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return score\n",
    "\n",
    "#Traverse all models to score.\n",
    "for name,model in zip(names,models):\n",
    "        score = RMSE(model,X_train, X_test, y_train, y_test)\n",
    "        print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46661,) (46661,)\n",
      "(46661, 1) (46661, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = models[4].predict(X_test)\n",
    "print(y_pred.shape,y_test.shape)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0],1)\n",
    "y_test = np.array(y_test).reshape(y_pred.shape[0],1)\n",
    "print(y_pred.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP-0 EMQ:  0.035985501743085305\n",
      "MLP-1 EMQ:  0.03777667666074362\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-810e759be1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhistories_nets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlocal_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/Python/env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "features_size = X_train.shape[1]\n",
    "\n",
    "nets = [];\n",
    "histories_nets = [];\n",
    "best_mlp = {'emq':10, 'index': 0}\n",
    "\n",
    "loss = 'mean_squared_error'\n",
    "n_neurons = 2\n",
    "n_epochs = 40\n",
    "learning_rate = 0.001\n",
    "bs = 30\n",
    "vs = 0.1\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10, \n",
    "                   baseline=None, restore_best_weights=True)\n",
    "mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "\n",
    "n_nets = 7\n",
    "\n",
    "for i in range(n_nets):\n",
    "    n_neurons = 2*n_neurons\n",
    "    input_l= Input(shape=(features_size,))\n",
    "    HL1 = Dense(units=n_neurons, activation='relu')(input_l)\n",
    "    output_l = Dense(units=n_outputs, activation='linear')(HL1)\n",
    "    MLP=Model(input_l, output_l)\n",
    "    nets.append(MLP)\n",
    "    nets[i].compile(optimizer=optimizer, loss=loss)\n",
    "    history = nets[i].fit(X_train, y_train,epochs=n_epochs,batch_size=bs,validation_split=vs,verbose=0,shuffle=True,callbacks=[es])\n",
    "    histories_nets.append(history)\n",
    "    local_y_pred = nets[i].predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, local_y_pred))\n",
    "    if(rmse < best_mlp['emq']):\n",
    "        best_mlp['emq'] = rmse\n",
    "        best_mlp['index'] = i\n",
    "    print(\"MLP-\"+str(i)+\" EMQ: \", rmse)\n",
    "    \n",
    "    \n",
    "print(\" \")\n",
    "print(\"A melhor √© MLP-\"+str(best_mlp['index'])+\" com RMSE: \", best_mlp['emq'])\n",
    "getLearningCurve(histories_nets[best_mlp['index']])\n",
    "#nets[best_mlp['index']].summary()\n",
    "#nets[(best_mlp['index'])].save('models/supervised/mlp_'+str(best_mlp['emq']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
